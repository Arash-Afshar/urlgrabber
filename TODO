ALPHA:

  * opener
    - fix broken opener caching - the implementation may depend on
      the next item
    - can we make it possible to include (or exclude) custom
      handlers in the openers?  Possibly just provide an "opener"
      option, although this would preclude the use of the "proxy"
      option.

  * threading/batch
    - (rt) propose an interface for threaded batch downloads
    - (mds) design a new progress-meter interface for threaded
      multi-file downloads
    - (rt) look at CacheFTPHandler and its implications for batch mode
      and byte-ranges/reget

  * web page
    - examples page
    - put up the software :)

ALPHA 2:

  * Add decent debugging code and a URLGRABBER_DEBUG environment
    variable so that users of miscellaneous applications can get the
    debugging output

  * Consider adding timeout keyword arg that would handle setting the socket
    timeout natively under python 2.3 or using timeoutsocket.py hack if 
    available and using python < 2.3.

  * Test proxy support with authenticating proxies (http and ftp).   

  * FTP proxy testing in general.

  * Have a plan for KeyboardInterupt exception handling. This is driven by 
    recent chatter on the yum list about Ctrl-C handling. Seth suggests 
    Ctrl-C as a "Skip to Next Mirror" trigger when processing MirrorGroups.

  * look at making the 'check_timestamp' reget mode work with ftp.
    Currently, we NEVER get a timestamp back, so we can't compare.
    We'll probably need to subclass/replace either the urllib2 FTP handler
    or the ftplib FTP object (or both, but I doubt it).  It may or may not
    be worth it just for this one mode of reget.  It fails safely - by
    getting the entire file.

  * ipv6

  * cache dns lookups -- for a possible approach, see
    https://lists.dulug.duke.edu/pipermail/yum-devel/2004-March/000136.html

Misc/Maybe:

  * BatchURLGrabber/BatchMirrorGroup for concurrent downloads and possibly to
    handle forking into secure/setuid sandbox.

  * Consider adding a progress_meter implementation that can be used in 
    concurrent download situations (I have some ideas about this -mds)
  
  * Consider using CacheFTPHandler instead of FTPHandler in byterange.py. 
    CacheFTPHandler reuses connections but this may lead to problems with
    ranges. I've tested CacheFTPHandler with ranges using vsftpd as a 
    server and everything works fine but this needs more exhaustive tests 
    or a fallback mechanism. Also, CacheFTPHandler breaks in the same way 
    keepalive breaks with multiple threads.

  * Consider some statistics tracking so that urlgrabber can record the 
    speed/reliability of different servers.  This could then be used by
    the mirror code for choosing optimal servers (slick, eh?)

  * check SSL certs.  This may require PyOpenSSL.
