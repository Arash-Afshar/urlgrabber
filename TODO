ALPHA:

  * mirror.py
    - (mds) make failover more controllable on a per-fetch basis.  For
      example, be able to control whether the _next index is incremented
      at all

  * options
    - (both) try and think of better/faster/cleaner ways to handle
      grabber options
    - (both) think about an interface for setting instance-level
      options for an already-created grabber (presumably, mg instances
      would support this for their options, too)

  * opener
    - (both) try and reduce the number of opener creations - try and
      use an instance-level opener for most fetches.

  * threading/batch
    - (rt) propose an interface for threaded batch downloads
    - (mds) look at making keepalive threadsafe
    - (mds) design a new progress-meter interface for threaded
      multi-file downloads
    - (rt) look at CacheFTPHandler and its implications for batch mode
      and byte-ranges/reget

  * reget
    - (mds) fix bug with self.opts; the reget code can modify
      self.opts in the URLGrabberFileObject, which _may_not_ be a copy
      of the grabber's opts.  Implementation will depend on what we
      decide to do with options.
    - (mds) do a little testing for ftp:// and file://

  * web page
    - (mds) make a proper web page describing the features, philosophy,
      intended audience, etc.  promote urlgrabber from "mini project" to
      full-fledged project

ALPHA 2:

  * Consider adding timeout keyword arg that would handle setting the socket
    timeout natively under python 2.3 or using timeoutsocket.py hack if 
    available and using python < 2.3.

  * Test proxy support with authenticating proxies (http and ftp).   

  * FTP proxy testing in general.

  * Have a plan for KeyboardInterupt exception handling. This is driven by 
    recent chatter on the yum list about Ctrl-C handling. Seth suggests 
    Ctrl-C as a "Skip to Next Mirror" trigger when processing MirrorGroups.

  * Make keepalive functionality work when used in multiple threads.
  
Misc/Maybe:

  * BatchURLGrabber/BatchMirrorGroup for concurrent downloads and possibly to
    handle forking into secure/setuid sandbox.

  * Consider adding a progress_meter implementation that can be used in 
    concurrent download situations (I have some ideas about this -mds)
  
  * Consider using CacheFTPHandler instead of FTPHandler in byterange.py. 
    CacheFTPHandler reuses connections but this may lead to problems with
    ranges. I've tested CacheFTPHandler with ranges using vsftpd as a 
    server and everything works fine but this needs more exhaustive tests 
    or a fallback mechanism. Also, CacheFTPHandler breaks in the same way 
    keepalive breaks with multiple threads.

  * Consider some statistics tracking so that urlgrabber can record the 
    speed/reliability of different servers.  This could then be used by
    the mirror code for choosing optimal servers (slick, eh?)
