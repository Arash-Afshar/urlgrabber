ALPHA:

  * Implement MirrorGroups.

ALPHA 2:

  * Handle non-satisfiable ranges. e.g. due to a server not supporting ranges 
    or a requested range being invalid. Right now the result of either of 
    these two cases is undefined and is probably different for HTTP/FTP.
    Raising an exception seems to be "the right thing to do" in both cases.

  * Consider adding timeout keyword arg that would handle setting the socket
    timeout natively under python 2.3 or using timeoutsocket.py hack if 
    available and using python < 2.3.

  * Clean up conditionals checking for urllib2 availability. Assume urllib2 
    is available.

  * Test proxy support with authenticating proxies (http and ftp).   

  * FTP proxy testing in general.

  * Have a plan for KeyboardInterupt exception handling. This is driven by 
    recent chatter on the yum list about Ctrl-C handling. Seth suggests 
    Ctrl-C as a "Skip to Next Mirror" trigger when processing MirrorGroups.

  * Reget support. When urlgrab is called, check if the file exists on disk. If
    so, offset the range so that we pull only the bytes remaining. This should
    probably have a kwarg to turn it on/off but could probably default to being
    on.
    
Misc/Maybe:

  * BatchURLGrabber/BatchMirrorGroup for concurrent downloads and possibly to
    handle forking into secure/setuid sandbox.

  * Make keepalive functionality work when used in multiple threads.
  
  * Consider adding a progress_meter implementation that can be used in concurrent 
    download situations.
  
  * Consider using CacheFTPHandler instead of FTPHandler in byterange.py. 
    CacheFTPHandler reuses connections but this may lead to problems with
    ranges. I've tested CacheFTPHandler with ranges using vsftpd as a 
    server and everything works fine but this needs more exhaustive tests 
    or a fallback mechanism. Also, CacheFTPHandler breaks in the same way 
    keepalive breaks with multiple threads.
